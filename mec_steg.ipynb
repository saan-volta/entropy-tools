{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d3b448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29bfa088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b75456ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd3fae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitarray import bitarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ef6e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e5dfe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis=-1):\n",
    "    # Subtract the maximum value for numerical stability\n",
    "    e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "    return e_x / np.sum(e_x, axis=axis, keepdims=True)\n",
    "\n",
    "def normalize(v):\n",
    "    assert len(np.where(v < 0)[0]) == 0\n",
    "    s = v.sum()\n",
    "    return v/s if s > 0 else v\n",
    "\n",
    "def entropy(p, axis=None, base=2):\n",
    "    p = np.asarray(p, dtype=float)\n",
    "    \n",
    "    # Handle zero probabilities: 0*log(0) = 0\n",
    "    # Only compute log for positive elements to avoid numerical issues\n",
    "    mask = p > 0\n",
    "    log_p = np.zeros_like(p)\n",
    "    log_p[mask] = np.log(p[mask]) / np.log(base)\n",
    "    \n",
    "    # Shannon entropy: H = -sum(p * log(p))\n",
    "    entropy = -np.sum(p * log_p, axis=axis)\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51fd14e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_partition(data, block_size):\n",
    "    bitdata = bitarray(data)\n",
    "    # pad\n",
    "    r = len(bitdata)%block_size\n",
    "    bitdata += bitarray('0'*(block_size-r) )\n",
    "#     print(len(bitdata))\n",
    "    assert len(bitdata) % block_size == 0\n",
    "    \n",
    "    blocks = []\n",
    "    for i in range(0, len(bitdata), block_size):\n",
    "        block = bitdata[i:i+block_size]\n",
    "        blocks.append(block)\n",
    "    return blocks\n",
    "\n",
    "def barr_to_int(barr):\n",
    "    val = 0\n",
    "    for bit in barr:\n",
    "        val = (val << 1) | bit\n",
    "    return val\n",
    "\n",
    "\n",
    "def int_to_barr(n: int, width: int = None) -> bitarray:\n",
    "    if n < 0:\n",
    "        raise ValueError(\"Only non-negative integers are supported.\")\n",
    "    if n == 0:\n",
    "        bits = bitarray('0')\n",
    "    else:\n",
    "        bits = bitarray()\n",
    "        while n > 0:\n",
    "            bits.append(n & 1)  # extract least significant bit\n",
    "            n >>= 1\n",
    "        bits.reverse()\n",
    "    \n",
    "    # Pad with leading zeros if width is specified\n",
    "    if width is not None:\n",
    "        if len(bits) > width:\n",
    "            raise ValueError(f\"Integer too large to fit in {width} bits\")\n",
    "        pad = bitarray('0' * (width - len(bits)))\n",
    "        bits = pad + bits\n",
    "    \n",
    "    return bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b62f3f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load small model (runs on CPU fine)\n",
    "model_name = \"distilgpt2\"  # or \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f0bed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_distribution(context: str, k: int = 10, decode=False):\n",
    "    # Encode context\n",
    "    inputs = tokenizer(context, return_tensors=\"pt\")\n",
    "    \n",
    "    # Forward pass (no gradient needed)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get logits for last token\n",
    "#     print(outputs.logits.shape)\n",
    "    logits = outputs.logits[:, -1, :]  # shape: [batch_size, vocab_size]\n",
    "#     print(logits.shape)\n",
    "    \n",
    "    # Convert to probabilities\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    \n",
    "    # Get top-k\n",
    "    topk_probs, topk_indices = torch.topk(probs, k)\n",
    "    \n",
    "    # Decode tokens\n",
    "    if decode:\n",
    "        topk_tokens = [tokenizer.decode([idx]) for idx in topk_indices[0]]\n",
    "        return list(zip(topk_tokens, topk_probs[0].tolist()))\n",
    "    else:\n",
    "        return topk_probs.numpy().squeeze(0), topk_indices.numpy().squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "083ccc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mec(p: np.array, q: np.array):\n",
    "    \"\"\"\n",
    "    Algorithm 1:  https://arxiv.org/pdf/1611.04035.pdf\n",
    "    We adjust Algorithm 1 and follow the advice in the text in order to reconstruct the matrix.\n",
    "\n",
    "    Supposedly has 1-bit guarantee - unfortunately not clear if equal to kacaoglu2\n",
    "\n",
    "    We require len(p) == q.\n",
    "    \"\"\"\n",
    "    p = p.copy()#.astype(np.longdouble)\n",
    "    p /= p.sum()\n",
    "    q = q.copy()#.astype(np.longdouble)\n",
    "    q /= q.sum()\n",
    "    \n",
    "    if p.shape[0] > q.shape[0]:\n",
    "        q = np.concatenate([q, np.zeros(p.shape[0]-q.shape[0]#, dtype=np.longdouble\n",
    "                                       )])\n",
    "    elif q.shape[0] > p.shape[0]:\n",
    "        p = np.concatenate([p, np.zeros(q.shape[0]-p.shape[0]#, dtype=np.longdouble\n",
    "                                       )])\n",
    "    assert len(p) == len(q), \"len(p) must be equal to len(q)!\"\n",
    "    # Joint distribution\n",
    "    J = np.zeros((q.shape[0], p.shape[0])#, dtype=np.longdouble\n",
    "                )  \n",
    "\n",
    "    # e = []\n",
    "    M = np.stack((p, q), 0)\n",
    "    r = M.max(axis=1).min()\n",
    "    while r > 0:\n",
    "        # e.append(r)\n",
    "        a_i = M.argmax(axis=1)\n",
    "        M[0, a_i[0]] -= r\n",
    "        M[1, a_i[1]] -= r\n",
    "        J[a_i[0], a_i[1]] = r\n",
    "        r = M.max(axis=1).min()\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31d2f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOCAB_SIZE = 50_257 # domain of covertext distribution\n",
    "\n",
    "def encode(ciphertext_bits_arr, context, steps, topk=40, block_size=10):\n",
    "    '''\n",
    "    Encode ciphertext into covertext.\n",
    "    \n",
    "    '''\n",
    "    mu_dom = 2**block_size\n",
    "    ct_blocks = block_partition(ciphertext_bits_arr, block_size)\n",
    "    ct_blocks_idxs = list(map(barr_to_int, ct_blocks))\n",
    "    mus = [np.ones(mu_dom,)/mu_dom for _ in ct_blocks] # init uniforms\n",
    "    mus_entropy = np.array([entropy(mu) for mu in mus])\n",
    "\n",
    "    # autoregressive conditional: p(C_j | C_1:j-1 = S_1:j-1)\n",
    "    C_ac_probs, C_ac_idxs = get_topk_distribution(context, k=topk, decode=False)  \n",
    "    S = []\n",
    "\n",
    "    step = 0\n",
    "    while step < steps:\n",
    "        print(f'Step: {step}')\n",
    "        istar = np.argmax(mus_entropy) # i in [0, len(mus)]\n",
    "        mu_istar = mus[istar]\n",
    "        # coupling\n",
    "        p, q = mu_istar, C_ac_probs\n",
    "        M = mec(p,q) # (mu_dom, topk)\n",
    "        M = M[:p.shape[0], :q.shape[0]] # eliminate padding 0s\n",
    "        # condition on realization of block\n",
    "        d_token = normalize(M[ct_blocks_idxs[istar]]) # (topk, 1)\n",
    "        print(f'\\tH( g(C_j|X_i* = x_i*) ): {entropy(d_token)}')\n",
    "\n",
    "        S_j_ix = np.random.choice(np.arange(0,topk), p=d_token) # S_j_ix is index in [0, topk]\n",
    "        S_j = C_ac_idxs[S_j_ix] # S_j is token index in [0, VOCAB_SIZE]\n",
    "        S.append(S_j)\n",
    "        # update context, generate new AC distribution\n",
    "        context += tokenizer.decode([S_j])\n",
    "        C_ac_probs, C_ac_idxs = get_topk_distribution(context, k=topk, decode=False)  \n",
    "        print(f'\\tContext: {context}')\n",
    "\n",
    "        # condition on realization of next token\n",
    "        mu_istar_prime = normalize(M[:, S_j_ix])\n",
    "        # update\n",
    "        mus[istar] = mu_istar_prime\n",
    "        mus_entropy[istar] = entropy(mu_istar_prime)\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    return S, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1d11d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_M = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d8da30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(S, context, steps, topk=40, block_size=10):\n",
    "#     block_size = 10\n",
    "#     ciphertext_bits_arr=bitarray(b'hello_world')\n",
    "#     context = 'The quick brown fox'\n",
    "#     S = tokenizer.encode('es on their way home. It has a nice warm, white face so let out a bit of')\n",
    "#     topk=40\n",
    "\n",
    "    mu_dom = 2**block_size\n",
    "    mus = [np.ones(mu_dom,)/mu_dom for _ in range(9)] # init uniforms\n",
    "    mus_entropy = np.array([entropy(mu) for mu in mus])\n",
    "    C_ac_probs, C_ac_idxs = get_topk_distribution(context, k=topk, decode=False)  \n",
    "\n",
    "    step = 0\n",
    "    while step < steps:\n",
    "#         print(f'Step: {step}')\n",
    "        istar = np.argmax(mus_entropy) # i in [0, len(mus)]\n",
    "        mu_istar = mus[istar]\n",
    "        # coupling\n",
    "        p, q = mu_istar, C_ac_probs\n",
    "        M = mec(p,q) # (mu_dom, topk)\n",
    "        \n",
    "        M = M[:p.shape[0], :q.shape[0]] # eliminate padding 0s\n",
    "        global_M = M.copy()\n",
    "        print(global_M)\n",
    "\n",
    "        S_j_ix = np.where(C_ac_idxs == S[step])[0].item()\n",
    "    #         S_j_ix = np.random.choice(np.arange(0,topk), p=d_token) # S_j_ix is index in [0, topk]\n",
    "    #         S_j = C_ac_idxs[S_j_ix] # S_j is token index in [0, VOCAB_SIZE]\n",
    "    #         S.append(S_j)\n",
    "        # update context, generate new AC distribution\n",
    "        context += tokenizer.decode([ S[step] ])\n",
    "        C_ac_probs, C_ac_idxs = get_topk_distribution(context, k=topk, decode=False)  \n",
    "#         print(f'\\tContext: {context}')\n",
    "\n",
    "        # condition on realization of next token\n",
    "        mu_istar_prime = normalize(M[:, S_j_ix])\n",
    "        # update\n",
    "        mus[istar] = mu_istar_prime\n",
    "        mus_entropy[istar] = entropy(mu_istar_prime)\n",
    "\n",
    "        step += 1\n",
    "       \n",
    "    \n",
    "    out_barr = bitarray('')\n",
    "    block_ids = []\n",
    "    for i in mus:\n",
    "        idcand = np.random.choice(np.arange(1024), p=i)\n",
    "        block_ids.append(idcand)\n",
    "        barr = int_to_barr(idcand, width=block_size)\n",
    "        out_barr += barr\n",
    "    return block_ids, out_barr.tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca86612f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      "\tH( g(C_j|X_i* = x_i*) ): -0.0\n",
      "\tContext: The quick brown foxes\n",
      "Step: 1\n",
      "\tH( g(C_j|X_i* = x_i*) ): -0.0\n",
      "\tContext: The quick brown foxes on\n",
      "Step: 2\n",
      "\tH( g(C_j|X_i* = x_i*) ): -0.0\n",
      "\tContext: The quick brown foxes on their\n",
      "Step: 3\n",
      "\tH( g(C_j|X_i* = x_i*) ): -0.0\n",
      "\tContext: The quick brown foxes on their way\n",
      "Step: 4\n",
      "\tH( g(C_j|X_i* = x_i*) ): -0.0\n",
      "\tContext: The quick brown foxes on their way home\n",
      "Step: 5\n",
      "\tH( g(C_j|X_i* = x_i*) ): -0.0\n",
      "\tContext: The quick brown foxes on their way home.\n",
      "Step: 6\n",
      "\tH( g(C_j|X_i* = x_i*) ): -0.0\n",
      "\tContext: The quick brown foxes on their way home. It\n",
      "Step: 7\n",
      "\tH( g(C_j|X_i* = x_i*) ): -0.0\n",
      "\tContext: The quick brown foxes on their way home. It has\n",
      "Step: 8\n",
      "\tH( g(C_j|X_i* = x_i*) ): -0.0\n",
      "\tContext: The quick brown foxes on their way home. It has a\n",
      "Step: 9\n",
      "\tH( g(C_j|X_i* = x_i*) ): -0.0\n",
      "\tContext: The quick brown foxes on their way home. It has a nice\n",
      "Step: 10\n",
      "\tH( g(C_j|X_i* = x_i*) ): -0.0\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm\n",
      "Step: 11\n",
      "\tH( g(C_j|X_i* = x_i*) ): -0.0\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm,\n",
      "Step: 12\n",
      "\tH( g(C_j|X_i* = x_i*) ): -0.0\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white\n",
      "Step: 13\n",
      "\tH( g(C_j|X_i* = x_i*) ): 0.9172182201768402\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white be\n",
      "Step: 14\n",
      "\tH( g(C_j|X_i* = x_i*) ): -0.0\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak\n",
      "Step: 15\n",
      "\tH( g(C_j|X_i* = x_i*) ): 1.8778646548780322\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-\n",
      "Step: 16\n",
      "\tH( g(C_j|X_i* = x_i*) ): 2.092069535850479\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back\n",
      "Step: 17\n",
      "\tH( g(C_j|X_i* = x_i*) ): 1.7008456745859637\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape\n",
      "Step: 18\n",
      "\tH( g(C_j|X_i* = x_i*) ): -0.0\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and\n",
      "Step: 19\n",
      "\tH( g(C_j|X_i* = x_i*) ): -0.0\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is\n",
      "Step: 20\n",
      "\tH( g(C_j|X_i* = x_i*) ): -0.0\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy\n",
      "Step: 21\n",
      "\tH( g(C_j|X_i* = x_i*) ): -0.0\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to\n",
      "Step: 22\n",
      "\tH( g(C_j|X_i* = x_i*) ): 2.2843194861933696\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see\n",
      "Step: 23\n",
      "\tH( g(C_j|X_i* = x_i*) ): -0.0\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.\n",
      "Step: 24\n",
      "\tH( g(C_j|X_i* = x_i*) ): 2.6518321258962922\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>\n",
      "Step: 25\n",
      "\tH( g(C_j|X_i* = x_i*) ): 3.297899630297687\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What\n",
      "Step: 26\n",
      "\tH( g(C_j|X_i* = x_i*) ): 1.591330797800809\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's\n",
      "Step: 27\n",
      "\tH( g(C_j|X_i* = x_i*) ): 3.8616615832992776\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not\n",
      "Step: 28\n",
      "\tH( g(C_j|X_i* = x_i*) ): 4.238674506424818\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always\n",
      "Step: 29\n",
      "\tH( g(C_j|X_i* = x_i*) ): 3.759400011341497\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always your\n",
      "Step: 30\n",
      "\tH( g(C_j|X_i* = x_i*) ): 4.031257933631246\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always your typical\n",
      "Step: 31\n",
      "\tH( g(C_j|X_i* = x_i*) ): 4.996689396679499\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always your typical Android\n",
      "Step: 32\n",
      "\tH( g(C_j|X_i* = x_i*) ): 3.333242516340464\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always your typical Android phone\n",
      "Step: 33\n",
      "\tH( g(C_j|X_i* = x_i*) ): 4.21296589793649\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always your typical Android phone is\n",
      "Step: 34\n",
      "\tH( g(C_j|X_i* = x_i*) ): 3.4396041235794597\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always your typical Android phone is a\n",
      "Step: 35\n",
      "\tH( g(C_j|X_i* = x_i*) ): 4.923840938917079\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always your typical Android phone is a very\n",
      "Step: 36\n",
      "\tH( g(C_j|X_i* = x_i*) ): 4.513892457493994\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always your typical Android phone is a very portable\n",
      "Step: 37\n",
      "\tH( g(C_j|X_i* = x_i*) ): 3.5579505302894514\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always your typical Android phone is a very portable phone\n",
      "Step: 38\n",
      "\tH( g(C_j|X_i* = x_i*) ): 2.861798612328378\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always your typical Android phone is a very portable phone.\n",
      "Step: 39\n",
      "\tH( g(C_j|X_i* = x_i*) ): 4.450924457212178\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always your typical Android phone is a very portable phone. However\n",
      "Step: 40\n",
      "\tH( g(C_j|X_i* = x_i*) ): 0.817399911958226\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always your typical Android phone is a very portable phone. However,\n",
      "Step: 41\n",
      "\tH( g(C_j|X_i* = x_i*) ): 4.51503331275377\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always your typical Android phone is a very portable phone. However, what\n",
      "Step: 42\n",
      "\tH( g(C_j|X_i* = x_i*) ): 3.928219209912246\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always your typical Android phone is a very portable phone. However, what it\n",
      "Step: 43\n",
      "\tH( g(C_j|X_i* = x_i*) ): 3.3545742552825897\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always your typical Android phone is a very portable phone. However, what it's\n",
      "Step: 44\n",
      "\tH( g(C_j|X_i* = x_i*) ): 3.287037909104786\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always your typical Android phone is a very portable phone. However, what it's worth\n",
      "Step: 45\n",
      "\tH( g(C_j|X_i* = x_i*) ): 1.675770902564877\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always your typical Android phone is a very portable phone. However, what it's worth is\n",
      "Step: 46\n",
      "\tH( g(C_j|X_i* = x_i*) ): 3.097613229399834\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always your typical Android phone is a very portable phone. However, what it's worth is just\n",
      "Step: 47\n",
      "\tH( g(C_j|X_i* = x_i*) ): 3.6100375374143425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always your typical Android phone is a very portable phone. However, what it's worth is just one\n",
      "Step: 48\n",
      "\tH( g(C_j|X_i* = x_i*) ): 3.8391480452111444\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always your typical Android phone is a very portable phone. However, what it's worth is just one small\n",
      "Step: 49\n",
      "\tH( g(C_j|X_i* = x_i*) ): 4.494296552080877\n",
      "\tContext: The quick brown foxes on their way home. It has a nice warm, white beak-back shape and is easy to see.<|endoftext|>What's not always your typical Android phone is a very portable phone. However, what it's worth is just one small addition\n"
     ]
    }
   ],
   "source": [
    "S, finaltext = encode(bitarray(b'hello_world'), 'The quick brown fox', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c539d95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[274,\n",
       " 319,\n",
       " 511,\n",
       " 835,\n",
       " 1363,\n",
       " 13,\n",
       " 632,\n",
       " 468,\n",
       " 257,\n",
       " 3621,\n",
       " 5814,\n",
       " 11,\n",
       " 2330,\n",
       " 307,\n",
       " 461,\n",
       " 12,\n",
       " 1891,\n",
       " 5485,\n",
       " 290,\n",
       " 318,\n",
       " 2562,\n",
       " 284,\n",
       " 766,\n",
       " 13,\n",
       " 50256,\n",
       " 2061,\n",
       " 338,\n",
       " 407,\n",
       " 1464,\n",
       " 534,\n",
       " 7226,\n",
       " 5565,\n",
       " 3072,\n",
       " 318,\n",
       " 257,\n",
       " 845,\n",
       " 17726,\n",
       " 3072,\n",
       " 13,\n",
       " 2102,\n",
       " 11,\n",
       " 644,\n",
       " 340,\n",
       " 338,\n",
       " 2861,\n",
       " 318,\n",
       " 655,\n",
       " 530,\n",
       " 1402,\n",
       " 3090]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "07dd7083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00097656 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.00097656 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.00097656 0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "[[0.00097656 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.00097656 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.00097656 0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.00055819 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.00052305 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "[[9.76562500e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.76562500e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.76562500e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 7.26990402e-06\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "[[0.00097656 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.00097656 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.00097656 0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.00056612 0.00041044 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "[[9.76562500e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.76562500e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.76562500e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 3.82009312e-05 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  4.48272651e-04 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 4.75590030e-04\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "[[0.00097656 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.00097656 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.00097656 0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.00035527]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.00058119 0.        ]]\n",
      "[[0.00097656 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.00097656 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.00097656 0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "[[0.00097656 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.00097656 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.00097656 0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.00058251 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.00055749]]\n",
      "[[9.76562500e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.76562500e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.76562500e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 4.17536590e-04\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.35627657e-07 0.00000000e+00 0.00000000e+00 ... 3.19606625e-06\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "[[0.00226423 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.00226423 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.00226423 0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "[[0.00233854 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.00233854 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.00233854 0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "[[0.00304479 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.00304479 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.00304479 0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0.01777401 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.01777401 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.01777401 0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([417, 598, 795, 111, 381, 886, 988, 620, 400], b'hello_world\\x00')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(S, 'The quick brown fox', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9b46de2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown foxes have never been known to have had a tendency to bite. They need to have a nice mouth.\n",
      "\n",
      "\n",
      "There are over 1,000 foxes on the continent in this genus - they have been found in Europe's most populated European states. This is because, since the beginning of the last great European European expansion, they have been around for many centuries in Europe\n"
     ]
    }
   ],
   "source": [
    "c2 = 'The quick brown fox'\n",
    "for _ in range(75):\n",
    "    probs, ixs = get_topk_distribution(c2, k=40, decode=False)\n",
    "    s_ix = torch.multinomial(torch.tensor(probs), 1)\n",
    "    c2 += tokenizer.decode([ ixs[s_ix] ])\n",
    "print(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82c4508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_joint_with_marginals(joint_dist, cmap=\"Blues\"):\n",
    "    \"\"\"\n",
    "    Plot a joint distribution as a heatmap with marginals.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    joint_dist : 2D numpy array\n",
    "    Discrete joint distribution (rows ~ X, cols ~ Y).\n",
    "    cmap : str\n",
    "    Colormap for the heatmap.\n",
    "    \"\"\"\n",
    "    joint_dist = np.array(joint_dist, dtype=float)\n",
    "    joint_dist /= joint_dist.sum() # normalize if not already\n",
    "\n",
    "\n",
    "    # Marginals\n",
    "    marg_x = joint_dist.sum(axis=1) # sum over Y\n",
    "    marg_y = joint_dist.sum(axis=0) # sum over X\n",
    "\n",
    "\n",
    "    # Figure layout\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    gs = gridspec.GridSpec(2, 2, width_ratios=[4, 1], height_ratios=[1, 4],\n",
    "    wspace=0.05, hspace=0.05)\n",
    "\n",
    "\n",
    "    ax_joint = fig.add_subplot(gs[1, 0])\n",
    "    ax_marg_x = fig.add_subplot(gs[0, 0], sharex=ax_joint)\n",
    "    ax_marg_y = fig.add_subplot(gs[1, 1], sharey=ax_joint)\n",
    "\n",
    "\n",
    "    # Heatmap (square aspect)\n",
    "    im = ax_joint.imshow(joint_dist, origin=\"lower\", aspect=\"equal\", cmap=cmap)\n",
    "    ax_joint.set_xlabel(\"Y\")\n",
    "    ax_joint.set_ylabel(\"X\")\n",
    "\n",
    "\n",
    "    # Marginals\n",
    "    ax_marg_x.bar(range(joint_dist.shape[1]), marg_y)\n",
    "    ax_marg_y.barh(range(joint_dist.shape[0]), marg_x)\n",
    "\n",
    "\n",
    "    # Clean axes\n",
    "    plt.setp(ax_marg_x.get_xticklabels(), visible=False)\n",
    "    plt.setp(ax_marg_y.get_yticklabels(), visible=False)\n",
    "\n",
    "\n",
    "    ax_marg_x.set_yticks([])\n",
    "    ax_marg_y.set_xticks([])\n",
    "\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
